{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f96fdd",
   "metadata": {},
   "source": [
    "## __1. 파이토치 텐서 선언하기(PyTorch Tensor Allocation)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99966f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301f37cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "1D Tensor (like vector)\n",
    "'''\n",
    "t = torch.FloatTensor([0., 1., 2., 3.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe40f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim()) # rank, 차원\n",
    "print(t.shape)\n",
    "print(t.size()) # .shape 와 .size()는 동일하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f07e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(3.)\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Numpy 처럼 인덱스 접근과 슬라이싱 가능하다.\n",
    "'''\n",
    "print(t[1], t[3]) # 인덱스 접근\n",
    "print(t[1:4]) # 슬라이싱 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395f037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2D Tensor (like matrix)\n",
    "'''\n",
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e332c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim())  # rank, 차원\n",
    "print(t.shape)\n",
    "print(t.size()) # .shape 과 .size()는 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d91e673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.) tensor(11.)\n",
      "tensor([[4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Numpy 처럼 인덱스 접근과 슬라이싱 가능하다.\n",
    "'''\n",
    "print(t[1][2], t[3][1]) # 인덱스 접근  (6., 11.)\n",
    "print(t[1:3][:]) # 슬라이싱 ([4., 5., 6.],[7., 8., 9.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2056f062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3D Tensor 도 동일하다. 넘어가자~\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3D Tensor 도 동일하다. 넘어가자~\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91928b8",
   "metadata": {},
   "source": [
    "## __2. 브로드캐스팅(Broadcasting)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361a6fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n크기가 다른 Tensor에 대해서 자동으로 크기를 맞춰서 연산을 수행하는 기능을 Broadcasing이라고 한다.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "크기가 다른 Tensor에 대해서 자동으로 크기를 맞춰서 연산을 수행하는 기능을 Broadcasing이라고 한다.\n",
    "크기가 1인 차원이 있는 경우에만 적용된다. 크기가 1인 차원을 연산 가능한 크기로 변경하여 연산을 한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b1300f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 6.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# vector + matrix\n",
    "m1 = torch.FloatTensor([[1, 2]])   # shape : 2, \n",
    "m2 = torch.FloatTensor([[3., 4.],[5., 6.]]) # shape : 2×2\n",
    "'''\n",
    "m1 : [1,2]         shape : 2,\n",
    "  -> [ [1, 2]\n",
    "       [1, 2] ]    shape : 2×2 로 변경된다.\n",
    "'''\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fbb8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "크기가 1인 차원을 갖지 않는 Tensor의 경우애는 Broadcasting 연산이 적용안됨\n",
    "'''\n",
    "m1 = torch.FloatTensor([[1, 2],[3., 4.]])   # shape : 2×2 \n",
    "m2 = torch.FloatTensor([[3., 4., 5.],[6., 7., 8.]]) # shape : 2×3\n",
    "#print(m1 + m2) # Error 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b278cc",
   "metadata": {},
   "source": [
    "## 3. __행렬곱(.matmul)과 원소곱(.mul)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dba070",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "행렬곱 (.matmul) : 일반적으로 배운 행렬의 곱셈 방법\n",
    "원소곱 (.mul) : element-wise 곱셈, 동일한 위치의 원소끼리 곱한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0c3fc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.],\n",
      "        [11.]])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1, 2], [3, 4]]) # shape : 2×2 \n",
    "m2 = torch.FloatTensor([[1], [2]])       # shape : 2×1\n",
    "print(m1.matmul(m2)) # 행렬곱이 성립하는 조건이므로 이상없이 연산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7749586",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-97cb44a2ea3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# 행렬곱이 성립하지 않는 조건이므로 Broadcasting 후 행렬곱 연산을 할까?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# -> 행렬곱의 경우는 Broadcasting 적용안된다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2)"
     ]
    }
   ],
   "source": [
    "print(m2.matmul(m1)) \n",
    "# 행렬곱이 성립하지 않는 조건이므로 Broadcasting 후 행렬곱 연산을 할까?\n",
    "# -> 행렬곱의 경우는 Broadcasting 적용안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a96f6435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nm2 : [ [1],[2] ]       shape : 2×1\\n ->  [ [1, 1],\\n       [2, 2]  ]       shape : 2×2\\n       \\nm1.mul(m2) :  \\n[  [1, 2],    [ [1, 1],      =>       [ [1, 2],\\n   [3, 4] ]     [2, 2] ]                [6, 8] ]\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m1.mul(m2)) # 두 Tensor의 크기가 다르므로 Broadcasting 후 원소곱을 한다.\n",
    "'''\n",
    "m2 : [ [1],[2] ]       shape : 2×1\n",
    " ->  [ [1, 1],\n",
    "       [2, 2]  ]       shape : 2×2\n",
    "       \n",
    "m1.mul(m2) :  \n",
    "[  [1, 2],    [ [1, 1],      =>       [ [1, 2],\n",
    "   [3, 4] ]     [2, 2] ]                [6, 8] ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1f012",
   "metadata": {},
   "source": [
    "## __4. 평균(mean), 합(sum)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cf5a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a17b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t.mean()) #.mean()은 전체 원소에 대한 평균을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ec16288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(t.mean(dim=0))\n",
    "print(t.mean(dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d02860f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndim=0 : 1번째 차원(행)\\n행에서의 평균을 계산하고, dim=0 차원을 제거한다.\\n\\n2번째 차원(열)만 남는다.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dim=0 : 1번째 차원(행)\n",
    "행에서의 평균을 계산하고, dim=0 차원을 제거한다.\n",
    "\n",
    "2번째 차원(열)만 남는다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea872560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5000, 3.5000])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(t.mean(dim=1)) # dim=1, 2번째 차원(열)의 평균을 계산하고, dim=1 차원을 제거한다.\n",
    "print(t.mean(dim=1).shape) # 2×2 -> 2×1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sum() 연산도 mean()연산과 동일하다.\n",
    ".sum() : 모든 원소의 합.\n",
    ".sum(dim=0) : dim=0인 원소들의 합을 계산하고, dim=0을 제거한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bcc3d7",
   "metadata": {},
   "source": [
    "## __5. 최대(max), 아그맥스(argmax)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd42abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ".max() : 원소의 최댓값을 반환한다.\n",
    ".max(dim=n) : n번째 dim에서 최대값을 반환하고, n번째 dim을 제거한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79bf1766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff91fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "print(t.max()) # Returns one value: max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70e8cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim=0)) # 1번째 dim (행)에서의 최대값을 반환한다. dim=0의 크기는 2이므로, 반환된 값은 2개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ".max(dim=n) 의 경우는 2개의 결과를 반환한다.\n",
    "value : n번째 dim에서의 최댓값들.\n",
    "indices : n번째 dim에서의 최댓값들의 인덱스. (argmax 라고도 한다.)\n",
    "\n",
    "value = .max(dim=n)[0]\n",
    "indices = .max(dim=n)[1]\n",
    "이런식으로도 받아올 수 있다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "505a0688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max:  tensor([3., 4.])\n",
      "Argmax:  tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print('Max: ', t.max(dim=0)[0])\n",
    "print('Argmax: ', t.max(dim=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4beb61e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
